#一、激活函数

在第一节中我们了解到，神经元不是单纯线性的，线性函数是只要有输入$x$，必定会有一个输出$y$与之对应，而神经元接收到信号不会马上做出响应，它会等待输入信号强度增大到超过阈值才会有输出，这就好比往杯子中倒水，只有水超过杯子的上边缘才会溢出来。所以，实际应用中我们会加入一个激活层，该激活层实际上是一些激活函数。在下图中，假设有三个输入，激活函数为$g(x)$，则最后的输出是$y=g(\alpha_{_{_1}}x_{{_1}}+\alpha_{_{_2}}x_{{_2}}+\alpha_{_{_3}}x_{{_3}})$，第一个神经元计算输入的加权和，然后通过第二个神经元激活函数的作用输出$y$。
<div align=center>
<img src='http://qiniu.xdpie.com/2018-05-17-15-57-50.png'>
<p style='text-align:center'>图1.2.1</p>
</div>

在神经网络中，激活函数的主要作用是引入非线性因素，解决线性模型不能解决的问题。上图中，为什么一定要做非线性变换而不直接输出$y=\alpha_{_{_1}}x_{{_1}}+\alpha_{_{_2}}x_{{_2}}+\alpha_{_{_3}}x_{{_3}}$呢？那是因为，线性输出$y$（也叫做预测值）会随着输入值的增大而无限增大，但有时候我们并不需要那么大的实际值，比如在做分类的时候，我们仅仅需要知道的是在某个阈值上下，$y$是为1（被激活）还是为0（未激活），通过判断1或者0就可以直接做出预测。另外，在上一节中，我们遇到一个特殊的情况，异或函数会让线性分类器无法把输入正确的归类，我们的解决办法是使用两个线性分类器，也许还有另一种办法，那就是使用圆把中间两个值圈起来，这种方法，其实就需要非线性变换。

激活函数在神经网络中的使用频率非常高，我们来看看常用的几个。
<b>阶跃函数</b>
为了模仿真正的生物神经元收到刺激后作出反应，我们在数学中首先想到的是阶跃函数。阶跃函数是在输入值未达到阈值后，输出一直为0，当输入达到阈值，输出值做突然的跳转，但这种冷冰冰，赤裸裸的尖锐边缘不太符合实际的应用，所以使用较少。
<div align=center>
<img src='http://qiniu.xdpie.com/2018-05-18-10-40-25.png'>
<p style='text-align:center'>图1.2.2</p>
</div>

<b>Sigmoid函数</b>
相对于阶跃函数的尖锐突出，Sigmoid函数显得要平滑很多，它的输出值范围为$(0,1)$，很容易和概率取值联系起来，因为这些特点，Sigmoid函数在神经网络中使用普遍。它的函数形式为：$$y=\frac{1}{1+e^{x}}$$
<div align=center>
<img src='http://qiniu.xdpie.com/2018-05-18-11-13-09.png'>
<p style='text-align:center'>图1.2.3</p>
</div>


既然线性分类器是一条线性线段，在数学中，我们可以把线段表示为$y=\alpha x+\beta $，$x$代表宽度，$y$代表长度，$\alpha$和$\beta$分别为直线的斜率和截距。而在神经网络中，我们把$x$称为输入，$y$称为输出，或者叫预测值，$\alpha$称为权重，$\beta$称为随机扰动项。如下图1.2.2所示的线性分类器。
<div align=center>
<img src='http://qiniu.xdpie.com/2018-05-17-11-07-30.png'>
<p style='text-align:center'>图1.2.2</p>
</div>








参考文献：
1、《Python神经网络编程》
2、https://www.zhihu.com/question/22334626