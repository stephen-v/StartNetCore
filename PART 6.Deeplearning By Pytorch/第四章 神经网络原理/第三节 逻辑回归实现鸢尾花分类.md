#实例：逻辑回归实现鸢尾花分类
我们收集到了一些鸢尾花数据集，部分数据如下表，在该数据集中有两种类别的鸢尾花各五十条，一共100条数据，数据集包括4个属性，分别是萼片长度，宽度，花瓣长度，宽度，其中在100条数据中，两类分别提取10条数据，共20条数据作为验证集，另外80条是训练集。采用Sigmoid函数做激活函数，再规定分类器输出1表示Iris-setosa(山鸢尾)品种，输出0表示Iris-Versicolour(变色鸢尾)。
<div align=center>
<img src='http://qiniu.xdpie.com/2018-05-29-10-14-15.png'>
<p style='text-align:center'>表1.2.2</p>
</div>

在进行机器学习之前，对数据集的可视化分析尤为重要，适当的可视化可以帮助我们快速有效的了解数据信息，并且大概地评估一下本次训练应使用何种模型，特别是对于二分类或多分类而言，节省数据的分析时间。在Python中，强大的matplotlib工具可以帮我们做到。
```python

import matplotlib.pyplot as plt
import xlrd

iris = xlrd.open_workbook('iris.xlsx')
table = iris.sheets()[0]
sepal_length_setosa = table.col_values(0)[1:50]
sepal_width_setosa = table.col_values(1)[1:50]
sepal_length_versicolor = table.col_values(0)[51:100]
sepal_width_versicolor = table.col_values(1)[51:100]

fig = plt.figure()
ax1 = fig.add_subplot(111)
ax1.set_title('sepal length and width scatter')
plt.xlabel('sepal length')
plt.ylabel('sepal width')
ax1.scatter(sepal_length_setosa, sepal_width_setosa, c='r', marker='o')
ax1.scatter(sepal_length_versicolor, sepal_width_versicolor, c='g', marker='o')
plt.show()
```
<div align=center>
<img src='http://qiniu.xdpie.com/2018-05-29-14-53-15.png'>
<p style='text-align:center'>图1.2.14</p>
</div>

上面的代码中我们使用了一个“xlrd”的工具来读取下载到的excel文件，但我建议把文件转化为csv类型，这样我们就可以使用readlines()读取文件，简化代码哦。
言归正传，我们仅仅使用了萼片长度和宽度两种特征来描绘鸢尾花的散点图，从上图可以看到两个品种的鸢尾花呈现出明显的线性关系，也就是说，可以使用一个线性分类器把两类别数据划分开，这正是我们希望看到的情形。
那么从现在起，我们会经常使用Python来表达数学问题和训练模型过程，按照以上分析的结果首先定义一个线性模型，我们把模型分为两层，第一层为输入层，第二层为输出层，没有隐藏层，同时初始化输入、输出、权重、学习率和Sigmoid激活函数。

```python
import numpy
import scipy.special


# linear network classify definition
class linearNetwork:
    # initialise the linear network
    def __init__(self, inputnodes, outputnodes, learningrate):
        # set number of nodes in each input, output layer
        self.inodes = inputnodes
        self.onodes = outputnodes

        self.wih = numpy.random.normal(0.0, pow(self.inodes, -0.5), (self.onodes, self.inodes))

        # learning rate
        self.lr = learningrate

        # activation function is the sigmoid function
        self.activation_function = lambda x: scipy.special.expit(x)

        pass
```

再来描绘一下我们的模型，如下图所示，第一层有4️个节点，第二层输出层有两个节点，并使用两个激活函数Sigmoid，在模型内部，输入层和输出层之间，我们分别用绿线代表输入信号和输出层第一个节点的连接，并且把输入信号赋予的权重改成绿色；同理，红线表示输入信号和输出层中第二个节点的连接，把输入信号赋予的权重用改成红色，这样方便我们看清信号在网络中的流动状态。这不是以上矩阵乘法中的线性分类器吗，太好了！矩阵的乘法将会又一次出现。
<div align=center>
<img src='http://qiniu.xdpie.com/2018-06-12-12-36-32.png'>
<p style='text-align:center'>图1.2.15</p>
</div>

处理样本数据时，我们把下载到的数据分成训练集和测试集，并分别放在两个csv文档中，训练集数据80条，测试集数据20条，数据量不大，这个工作需要我们手动来完成。

定义好了线性模型后，我们需要定义如何训练模型和测试模型。如下代码所示，记得把整个模型保存在一个python文件中，为后续的训练和测试调用。
```python
import numpy
import scipy.special


# linear network classify definition
class linearNetwork:
    # initialise the linear network
    def __init__(self, inputnodes, outputnodes, learningrate):
        # set number of nodes in each input, output layer
        self.inodes = inputnodes
        self.onodes = outputnodes

        self.wih = numpy.random.normal(0.0, pow(self.inodes, -0.5), (self.onodes, self.inodes))

        # learning rate
        self.lr = learningrate

        # activation function is the sigmoid function
        self.activation_function = lambda x: scipy.special.expit(x)

        pass

    # train the linear network
    def train(self, inputs_list, targets_list):
        inputs = numpy.array(inputs_list, ndmin=2).T
        targets = numpy.array(targets_list, ndmin=2).T
        # calculate signals into final output layer
        final_inputs = numpy.dot(self.wih, inputs)
        # calculate the signals emerging from final output layer
        final_outputs = self.activation_function(final_inputs)

        # output layer error is the (target - actual)
        output_errors = targets - final_outputs

        # update the weights for the links between the hidden and output layers
        self.wih += self.lr * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)),
                                        numpy.transpose(inputs))


    # query the linear network
    def query(self, inputs_list):
        # calculate signals into linear output layer
        linear_output = numpy.dot(self.wih, inputs_list)
        # calculate the signals emerging from final output layer
        final_outputs = self.activation_function(linear_output)

        return final_outputs

```
紧接着就是训练模型，我们先把存放在csv文件上的数据导入一个list中，即使得输入信号为如下形式：
$$
\begin{bmatrix}
 [5.1&  3.5&1.4  &0.2 ]\\ 
 [4.9&  3&1.4  &0.2 ]\\ 
 [4.7&3.2  &1.3  &0.2] \\ 
 ...&...  &...  &... 
\end{bmatrix}
$$

```python
# load the iris training data into a list
training_data_file = open("iris_train.csv", 'r')
training_data_list = training_data_file.readlines()
training_data_file.close()

```
数据准备好后，可以开始训练模型，首先我们根据原数据特性来设置输入节点个数（4个输入信号，分别是萼片长度、萼片宽度、花瓣长度、花瓣宽度）、输出节点个数（2个，用于最后判断是0还是1，1表示山鸢尾花，0表示变色鸢尾花）、学习率（0.01）、训练的迭代次数（1000次）、以及调用之前定义的模型。
```python
# number of input, output nodes,and learning rate
input_nodes = 4
output_nodes = 2
learning_rate = 0.01
# epochs is the number of times the training data set is used for training
epochs = 1000
# create instance of linear network
n = linear_classify.linearNetwork(input_nodes, output_nodes, learning_rate)

```
训练正式开始，一定要记住，训练完成后需要把最优的权重值保存为一个文件，以供验证模型时使用。这里，我们保存的文件名为win.npy。以下代码中的target表示目标预测值。
```python
# train the linear network
for e in range(epochs):
    # go through all records in the training data set
    print('start training, epoch:', e)
    for record in training_data_list:
        # split the record by the ',' commas
        record = record.replace('\n', '').split(',')
        record = [float(data) for data in record]
        input_data = (np.asfarray(record[0:4]) / 10.0 * 0.99) + 0.01
        true_lable = int(record[-1])
        # create the target output values (all 0.01, except the desired label which is 0.99)
        targets = np.zeros(output_nodes) + 0.01
        targets[true_lable] = 0.99
        n.train(input_data, targets)
        pass
    np.save('wih.npy', n.wih)
    pass

```
训练的迭代次数会影响模型的好坏，我们在本次训练中，由于训练数据仅有几十条，因此，迭代1000次完全足够了。在训练完模型后，我们保存了最优的权重值，在验证模型时，需要使用这些最优权重来做测试集数据的验证。但是如何判断模型的好坏呢？一般我们用几个指标来衡量，准确率，召回率，F值等等。

准确率和召回率是广泛用于信息检索和统计学分类领域的两个度量值，用来评价结果的质量。其中准确率是指正确预测出的样本数与全部样本数的比率，衡量的是模型的查准率，即预测出的类别有多少是准确的（包括正负两种样本）；召回率是指对所关注的某个类别，预测出的正确样本数和该类别样本总数的比率，衡量的是模型的查全率，即所有正样本或负样本有多少被预测正确了；F值指当准确率和召回率存在矛盾时，综合准确率和召回率这两种评估指标，用于综合反映整体的指标，是两者的调和平均值。
**准确率（Precision）**
<div style='text-align:center'>准确率 = 正确预测出的样本数 / 样本总数</div>

**召回率（Recall）**
<div style='text-align:center'>召回率 = 正确预测出的正样本数 / 正样本总数 </div>
<div style='text-align:center;padding:10px 0'>或者为 </div>
<div style='text-align:center'>召回率 = 正确预测出的负样本数 / 负样本总数 </div>

**F值（F-Measure）**
<div style='text-align:center;padding:0 0 20px 0'>F = 准确率*召回率*2 / (准确率 + 召回率)</div>

比如，以上鸢尾花的测试集有正样本数山鸢尾花10条，负样本数变色鸢尾花10条，总共20条样本，假设我们的模型正确预测出了山鸢尾花9条，变色鸢尾花8条，那么我们模型的准确率就为：
$$P=\frac{9+8}{20}=\frac{17}{20}=0.85$$
如果关注的是模型能够正确预测出山鸢尾花，则模型召回率为：
$$R=\frac{9}{10}=0.9$$
如果关注的是模型能够正确预测出变色鸢尾花，则模型召回率为：
$$R=\frac{8}{10}=0.8$$

至于F值，按照验证结果，使用准确率和召回率带入计算就可以了。因此了解到评估模型的几个性能指标后，我们才可以开始正式验证线性模型的表现力。

以下代码中，省略了数据的导入，该部分与训练模型的时候一样。验证时，我们把模型最后输出节点上的两个概率值取最大概率值的索引坐标，并与真实label做对比，如果和真实值一样，则统计为1，如果不相同，则统计为0；最后，用统计的0，1值来计算模型的准确率。
```python
# go through all the records in the test dataset
n.wih = np.load('wih.npy')
scorecard = []
for record in testing_data_list:
    record = record.replace('\n', '').split(',')
    record = [float(data) for data in record]
    input_data = (np.asfarray(record[0:4]) / 10.0 * 0.99) + 0.01
    # true label is the last one in record
    true_label = int(record[-1])
    # query the network
    outputs = n.query(input_data)
    # the index of the highest value corresponds to the label
    label = np.argmax(outputs)
    # append correct or incorrect to list
    if label == true_label:
        scorecard.append(1)
    else:
        scorecard.append(0)
    pass

# calculate the performance score, the fraction of correct answers
scorecard_array = np.asarray(scorecard)
print("performance = ", scorecard_array.sum() / scorecard_array.size)

```
不出所料，我们得出的准确率为：
```python
0.95

```

这个结果对仅用100多条数据来进行训练过的模型来说应该很不错了，如果我们还想提高准确率，一个办法是增加样本数量，这种方法毫无疑问能够提高模型的准确率，并且这种方法适用于任何网络或模型。另外一种办法就是改变我们的模型，比如采用SVM，以及适当增加神经网络的深度等等，不过，不同的方法还是要根据不同的分类要求来使用才能发挥最好的效果。

好了，通过这一节我们逐步清晰了逻辑回归模型的工作原理，输入信号是怎么在网络中流动的，以及最后输出是些什么信号，这些细节无疑对于我们后续了解更复杂的网络打下坚实的基础。

最后，请闭上眼睛，让神经网络在脑海里再漫游一次，让我们再编织一次网络模型，让数据再一次在模型中流动。睁开眼，带着愉悦的心情走向下一个里程。

**附录：**
完整代码：https://github.com/stephen-v/simple-nerual-network/tree/master/linear_classify

iris数据集下载，百度云盘：https://pan.baidu.com/s/1Ia9PHzJOMv6BAGTEj0m9uQ   密码：ytn6